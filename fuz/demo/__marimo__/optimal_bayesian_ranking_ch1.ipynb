{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {},
   "source": [
    "# optimal bayesian ranking\n",
    "<h3 align='center'>chapter 1: bernoulli to beta</h3>\n",
    "<p align='center'>by miraia s. chiou © 2024</p>\n",
    "\n",
    "## introduction\n",
    "\n",
    "**fuz** can be used to improve on basic bayesian ranking by taking into account the shape of distributions rather than just the means. the optimal method is to use mode-parameterized beta or dirichlet distributions, but using a prior obtained by multiplicative pooling (aka upco) also improves upon traditional [bayesian averaging/ranking](https://en.wikipedia.org/wiki/Bayesian_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "## the bernoulli distribution\n",
    "\n",
    "to understand how my optimal bayesian ranking algorithm works, start with the bernoulli distribution. this can be thought of as coin flips, upvotes and downvotes, yes/no ratings, or anything representable as binary. as an example the video game service _steam_ uses yes/no (thumbs up or thumbs down). in this case, a game with 6 thumbs up and 2 thumbs down has a bernoulli score distribution with $p=0.75$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "wintro_score = mo.ui.slider(\n",
    "    0, 1, 0.01, value=0.75, show_value=True, label='choose a score', full_width=True\n",
    ")\n",
    "mo.callout(wintro_score, kind='success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "intronoulli = bernoulli(wintro_score.value)\n",
    "intronoulli_p = [intronoulli.pmf(0), intronoulli.pmf(1)]\n",
    "_chart = (\n",
    "    plot_bernoulli(intronoulli_p).properties(width=400).configure_mark(color='darkgreen')\n",
    ")\n",
    "mo.ui.altair_chart(_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {},
   "source": [
    "this distribution represents the sample mean. however, we have some additional information we want to represent - the number of ratings (count). we can do this with the binomial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {},
   "source": [
    "## bernoulli to binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "wintro_no = mo.ui.slider(\n",
    "    0, 10, value=2, show_value=True, label='\\# of no/tails/downvotes', full_width=True\n",
    ")\n",
    "wintro_yes = mo.ui.slider(\n",
    "    0, 10, value=6, show_value=True, label='\\# of yes/heads/upvotes', full_width=True\n",
    ")\n",
    "mo.callout(mo.hstack([wintro_no, wintro_yes], widths='equal', align='center'), kind='info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro2_weights = np.array([wintro_no.value, wintro_yes.value])\n",
    "intro2_p = flog.norm(intro2_weights)\n",
    "intro2_n = intro2_weights.sum()\n",
    "mo.md(f\"\"\"\n",
    "here i introduce `fuz.log.lnorm` which can stably normalize weights in logarithmic space (log -> log), handling `nan`s and complex numbers. a little excessive for our example here, but works well with very small probabilities. if you want to move out of log space, a convenience function, `norm`, does log conversion and exponentiation for you.\n",
    "\n",
    "```python\n",
    "import fuz.log as flog\n",
    "import numpy as np\n",
    "\n",
    "flog.norm({intro2_weights}) # {intro2_p}\n",
    "# this is equivalent to:\n",
    "np.exp(flog.lnorm(np.log({intro2_weights}))) # {intro2_p}\n",
    "```\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "intronomial = binom(intro2_n, intro2_p[1])\n",
    "_noulli_chart = plot_bernoulli(intro2_p)\n",
    "_nomial_chart = plot_binomial(intronomial).properties(\n",
    "    title=alt.TitleParams(\n",
    "        text='binomial pmf',\n",
    "        subtitle=f'n={intro2_n}, heads={wintro_yes.value}, tails={wintro_no.value}',\n",
    "    )\n",
    ")\n",
    "mo.hstack([mo.ui.altair_chart(_noulli_chart), mo.ui.altair_chart(_nomial_chart)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.md(f\"\"\"\n",
    "this is how the binomial distribution is typically first taught. the pmf shows the probability of $h$ successes, given $n$ trials. however, for bayesian ranking, this isn't what we need. \n",
    "\n",
    "what we really want is to quantify the uncertainty around possible true scores. i.e., given {wintro_yes.value} heads and {wintro_no.value} tails, what's the probability that once we have $\\infty$ ratings, the score will be $x$?\n",
    "\n",
    "good news - we can still start with the binomial distribution!\n",
    "\n",
    "we use the formula of the binomial pmf to hold $k$ and $n$ constant, sweeping $x$ to get probabilities and creating a chart.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {},
   "source": [
    "## binomial to beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_xlen = mo.ui.slider(5, 50, value=5, full_width=True, label='slide to sample!')\n",
    "mo.callout(w_xlen, kind='danger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_interactive = np.linspace(0, 1, w_xlen.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pl.DataFrame(\n",
    "    {\n",
    "        'true mean': x_interactive,\n",
    "        'probability': binom.pmf(wintro_yes.value, intro2_n, x_interactive),\n",
    "    }\n",
    ")\n",
    "_base = alt.Chart(\n",
    "    _df,\n",
    "    title=alt.TitleParams(\n",
    "        text='probability of potential true means',\n",
    "        subtitle=f'given {wintro_yes.value} heads and {wintro_no.value} tails',\n",
    "    ),\n",
    ").encode(alt.X('true mean'), alt.Y('probability'))\n",
    "_line = _base.mark_line(color='maroon')\n",
    "_point = _base.mark_point(color='maroon')\n",
    "_chart = _line + _point\n",
    "_chart.properties(width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {},
   "source": [
    "what do you notice here?\n",
    "\n",
    "1. this is not a probability distribution function (pdf) yet. to make it a pdf, we'll divide the probability by the integral to get the density.\n",
    "1. the mode (peak) is $p$.\n",
    "1. the mean of the possible true means is different from the mode.\n",
    "1. after turning this into a pdf, this is a beta distribution.\n",
    "\n",
    "let's turn this into a pdf and see which beta distributions might match. fortunately **fuz** allows you to make beta distributions in a variety of ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "import fuz.dists as fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_small = np.linspace(0, 1, 257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_betas(x: np.ndarray, pdfs: Sequence[Callable], names: Sequence[str]) -> alt.Chart:\n",
    "    dfs = []\n",
    "    for pdf, name in zip(pdfs, names, strict=True):\n",
    "        bdf = pl.DataFrame({'x': x, 'pdf': pdf(x)}).with_columns(name=pl.lit(name))\n",
    "        dfs.append(bdf)\n",
    "    df = pl.concat(dfs)\n",
    "    base = alt.Chart(df, title=name).encode(\n",
    "        alt.X('x'), alt.Y('pdf'), alt.Color('name'), alt.StrokeDash('name')\n",
    "    )\n",
    "    return base.mark_line(opacity=0.5, strokeWidth=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pdf = lambda x: binom.pmf(wintro_yes.value, intro2_n, x)\n",
    "bin_pdf = lambda x: pre_pdf(x) / quad(pre_pdf, 0, 1)[0]\n",
    "_bin_df = pl.DataFrame({'x': x_small, 'pdf': bin_pdf(x_small)}).with_columns(\n",
    "    name=pl.lit('binomial-derived')\n",
    ")\n",
    "_bin_fig = (\n",
    "    alt.Chart(_bin_df, title='binomial-derived vs potential betas')\n",
    "    .mark_line()\n",
    "    .encode(alt.X('x'), alt.Y('pdf'), alt.Color('name'), alt.StrokeDash('name'))\n",
    ")\n",
    "\n",
    "_mo = intro2_p[1]\n",
    "b_mo_t = fd.beta_from_mode_trials(_mo, intro2_n)\n",
    "b_mo_k1 = fd.beta_from_mode_k(_mo, intro2_n)\n",
    "b_mu_k1 = fd.beta_from_mu_k(_mo, intro2_n)\n",
    "_beta_fig = plot_betas(\n",
    "    x_small, (b_mo_t.pdf, b_mo_k1.pdf, b_mu_k1.pdf), ('β mode trials', 'β mode k', 'β μ k')\n",
    ")\n",
    "\n",
    "mo.ui.altair_chart(_bin_fig + _beta_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ulZA",
   "metadata": {},
   "source": [
    "from the chart, it's clear that the beta distribution parameterized by mode and number of trials matches the binomial-derived pdf.\n",
    "\n",
    "what are the implications? moving from bernoulli to binomial to beta is a well-known fundamental concept in statistics, so what's new here? let's set things up to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfG",
   "metadata": {},
   "source": [
    "## setup\n",
    "\n",
    "first, for the purposes of this chapter, let's define:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu_s &= \\text{sample mean} \\\\\n",
    "\\mu_\\top &= \\text{the true mean} \\\\\n",
    "\\mu_\\diamond &= \\text{a possible true mean} \\\\\n",
    "\\Mu &= \\text{the distribution of possible true means} \\\\\n",
    "\\mathrm{E}[M] = \\mu_\\Mu &= \\text{the mean of possible true means} \\\\\n",
    "\\hat{\\Mu} &= \\text{the mode of the possible true mean distribution} \\\\\n",
    "\\hat{\\Beta} &= \\text{the mode of a beta distribution} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "in addition, we use standard notation for the [beta distribution from wikipedia](https://en.wikipedia.org/wiki/Beta_distribution).\n",
    "\n",
    "here are some insights:\n",
    "\n",
    "1. the parameterization of the beta by mode and no. of trials $t$, where $t = k-2$, matches best.\n",
    "1. the mean of the beta $\\mu_B$ corresponds to the mean of possible true means $\\mu_\\Mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pvdt",
   "metadata": {},
   "source": [
    "## claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBYS",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.callout(\n",
    "    mo.md(r\"\"\"\n",
    "\n",
    "1. in a ranking context, taking $\\mu_\\Mu$ is equivalent to finding the posterior, where the prior consists of the other items' possible true mean distributions $M_i$.\n",
    "1. this is extensible other rating systems like 3-star, 5-star, out-of-10, and even continuous (floating-point) systems, by using dirichlet distributions.\n",
    "1. given the same information, finding $\\mu_\\Mu$ is optimal and outperforms other bayesian ranking algorithms [^same-level]\n",
    "\n",
    "[^same-level]: caveat being algorithms on the same level; i'm not comparing to complex recommender systems, although it could act as a basis for a better recommender system since incorporating weights is simple.\n",
    "\"\"\"),\n",
    "    kind='warn',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aLJB",
   "metadata": {},
   "source": [
    "i will address these claims in the following chapters.\n",
    "\n",
    "i believe this is a novel angle to look at the problem of bayesian ranking, although i wouldn't be surprised if someone has done something similar before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nHfw",
   "metadata": {},
   "source": [
    "## the mean of possible true means\n",
    "\n",
    "first, what's the best way to calculate $\\mu_\\Mu$? just a bit of algebra:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "t &= k-2 \\\\\n",
    "k &= \\alpha + \\beta \\\\\n",
    "\\hat{\\Beta} &\\coloneqq \\mu_s\\\\\n",
    "\\hat{\\Beta} &= \\frac{\\alpha-1}{\\alpha+\\beta-2} = \\frac{\\alpha-1}{t} \\\\\n",
    "\\Mu &= \\Beta(\\alpha,\\beta) \\\\\n",
    "\\mu_\\Mu &= \\frac{\\alpha}{k} \\\\\n",
    "\\alpha &= k\\mu_\\Mu = t\\hat{\\Beta} + 1 \\\\\n",
    "\\mu_\\Mu &= \\frac{t \\mu_s + 1}{k} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "thus, to find $\\mu_\\Mu$ given number of ratings $t$ and mean $\\mu_s$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xXTn",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.callout(\n",
    "    mo.md(r\"\"\"\n",
    "$$\n",
    "\\mu_\\Mu = \\frac{t \\mu_s + 1}{t+2}\n",
    "$$\n",
    "\"\"\"),\n",
    "    kind='success',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AjVT",
   "metadata": {},
   "source": [
    "## code navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pHFh",
   "metadata": {},
   "source": [
    "### widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NCOB",
   "metadata": {},
   "source": [
    "#### initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aqbW",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_n_items = mo.ui.slider(\n",
    "    steps=[5, 10, 50, 100, 500, 1000],\n",
    "    debounce=True,\n",
    "    label='no. of scored items',\n",
    "    full_width=True,\n",
    "    show_value=True,\n",
    "    value=10,\n",
    ")\n",
    "w_init_possible_means = mo.ui.range_slider(\n",
    "    0.01,\n",
    "    0.99,\n",
    "    0.01,\n",
    "    value=(0.05, 0.95),\n",
    "    debounce=True,\n",
    "    show_value=True,\n",
    "    label='possible mean scores',\n",
    "    full_width=True,\n",
    ")\n",
    "w_init_n_scores = mo.ui.range_slider(\n",
    "    2,\n",
    "    200,\n",
    "    1,\n",
    "    value=(3, 36),\n",
    "    debounce=True,\n",
    "    label='possible no. of scores',\n",
    "    full_width=True,\n",
    "    show_value=True,\n",
    ")\n",
    "w_xax_resolution = mo.ui.slider(\n",
    "    steps=[129, 257, 513, 1025, 2049, 4097, 8193],\n",
    "    debounce=True,\n",
    "    label='x axis resolution',\n",
    "    full_width=True,\n",
    "    show_value=True,\n",
    "    value=1025,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TRpd",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TXez",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bernoulli(p: Sequence[float, float] | np.ndarray) -> alt.Chart:\n",
    "    _df = pl.DataFrame({'x': ['negative', 'positive'], 'probability': p})\n",
    "    _base = alt.Chart(_df, title='bernoulli probability mass function (pmf)').encode(\n",
    "        alt.X('x', axis=alt.Axis(labelAngle=0)),\n",
    "        alt.Y('probability', scale=alt.Scale(domain=[0, 1])),\n",
    "    )\n",
    "    _bar = _base.mark_bar()\n",
    "    _text = _base.mark_text(dy=-10).encode(alt.Text('probability', format='.2f'))\n",
    "    return _bar + _text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dNNg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binomial(dist: rv_discrete_frozen, max_n: int = 20) -> alt.Chart:\n",
    "    x = np.arange(max_n + 1)\n",
    "    df = pl.DataFrame({'successes': x, 'probability': dist.pmf(x)})\n",
    "    base = alt.Chart(df, title='binomial pmf').encode(\n",
    "        alt.X('successes'), alt.Y('probability')\n",
    "    )\n",
    "    line = base.mark_line()\n",
    "    point = base.mark_point()\n",
    "    return line + point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yCnT",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wlCL",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import marimo as mo\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from scipy.stats._distn_infrastructure import rv_continuous_frozen, rv_discrete_frozen\n",
    "\n",
    "import fuz.log as flog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kqZH",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
